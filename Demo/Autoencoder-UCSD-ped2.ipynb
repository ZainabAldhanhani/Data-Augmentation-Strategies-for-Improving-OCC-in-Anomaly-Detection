{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss=0.030610\n",
      "Epoch 2/50, Loss=0.002876\n",
      "Epoch 3/50, Loss=0.002173\n",
      "Epoch 4/50, Loss=0.001766\n",
      "Epoch 5/50, Loss=0.001468\n",
      "Epoch 6/50, Loss=0.001309\n",
      "Epoch 7/50, Loss=0.001194\n",
      "Epoch 8/50, Loss=0.001125\n",
      "Epoch 9/50, Loss=0.001070\n",
      "Epoch 10/50, Loss=0.001023\n",
      "Epoch 11/50, Loss=0.000983\n",
      "Epoch 12/50, Loss=0.000947\n",
      "Epoch 13/50, Loss=0.000914\n",
      "Epoch 14/50, Loss=0.000884\n",
      "Epoch 15/50, Loss=0.000856\n",
      "Epoch 16/50, Loss=0.000832\n",
      "Epoch 17/50, Loss=0.000812\n",
      "Epoch 18/50, Loss=0.000792\n",
      "Epoch 19/50, Loss=0.000776\n",
      "Epoch 20/50, Loss=0.000762\n",
      "Epoch 21/50, Loss=0.000747\n",
      "Epoch 22/50, Loss=0.000751\n",
      "Epoch 23/50, Loss=0.001460\n",
      "Epoch 24/50, Loss=0.001684\n",
      "Epoch 25/50, Loss=0.001595\n",
      "Epoch 26/50, Loss=0.001271\n",
      "Epoch 27/50, Loss=0.001233\n",
      "Epoch 28/50, Loss=0.000517\n",
      "Epoch 29/50, Loss=0.000417\n",
      "Epoch 30/50, Loss=0.000426\n",
      "Epoch 31/50, Loss=0.000432\n",
      "Epoch 32/50, Loss=0.000435\n",
      "Epoch 33/50, Loss=0.000438\n",
      "Epoch 34/50, Loss=0.000439\n",
      "Epoch 35/50, Loss=0.000440\n",
      "Epoch 36/50, Loss=0.000351\n",
      "Epoch 37/50, Loss=0.000335\n",
      "Epoch 38/50, Loss=0.000331\n",
      "Epoch 39/50, Loss=0.000326\n",
      "Epoch 40/50, Loss=0.000325\n",
      "Epoch 41/50, Loss=0.000330\n",
      "Epoch 42/50, Loss=0.000334\n",
      "Epoch 43/50, Loss=0.000337\n",
      "Epoch 44/50, Loss=0.000338\n",
      "Epoch 45/50, Loss=0.000339\n",
      "Epoch 46/50, Loss=0.000340\n",
      "Epoch 47/50, Loss=0.000303\n",
      "Epoch 48/50, Loss=0.000298\n",
      "Epoch 49/50, Loss=0.000296\n",
      "Epoch 50/50, Loss=0.000293\n",
      "AUC=0.5576,Acc=0.3856,F1=0.4172\n",
      "CM:\n",
      "[[ 333   29]\n",
      " [1206  442]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.22      0.92      0.35       362\n",
      "     Anomaly       0.94      0.27      0.42      1648\n",
      "\n",
      "    accuracy                           0.39      2010\n",
      "   macro avg       0.58      0.59      0.38      2010\n",
      "weighted avg       0.81      0.39      0.41      2010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from pytorch_msssim import ssim  # pip install pytorch-msssim\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1. Dataset loader for UCSD Ped2\n",
    "default_transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "class UCSDPed2Dataset(Dataset):\n",
    "    def __init__(self, root, phase='training', transform=None, gt_list=None):\n",
    "        self.phase = phase\n",
    "        self.transform = transform or default_transform\n",
    "        subdir = 'Train' if phase == 'training' else 'Test'\n",
    "        base = os.path.join(root, subdir)\n",
    "        vids = sorted([d for d in os.listdir(base) if os.path.isdir(os.path.join(base, d))])\n",
    "        self.paths = []\n",
    "        self.labels = []\n",
    "        for vid in vids:\n",
    "            frame_dir = os.path.join(base, vid)\n",
    "            for ext in ('*.png', '*.jpg', '*.jpeg', '*.tif'):\n",
    "                for p in sorted(glob.glob(os.path.join(frame_dir, ext))):\n",
    "                    self.paths.append(p)\n",
    "                    if phase == 'testing' and gt_list is not None:\n",
    "                        frame_idx = int(os.path.splitext(os.path.basename(p))[0])\n",
    "                        # vid is like 'Test001' or 'Train001'\n",
    "                        vid_idx = int(re.sub('[^0-9]', '', vid)) - 1\n",
    "                        self.labels.append(1 if frame_idx in gt_list[vid_idx] else 0)\n",
    "                    else:\n",
    "                        self.labels.append(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.paths[idx]).convert('L')\n",
    "        x = self.transform(img)\n",
    "        return (x, self.labels[idx]) if self.phase == 'testing' else x\n",
    "\n",
    "# 2. Load ground truth from .m file in root or Test folder\n",
    "import glob, os, re\n",
    "\n",
    "def load_ucsd_gt(root):\n",
    "    # look for the .m file in the Test/ folder\n",
    "    m_files = glob.glob(os.path.join(root, 'Test', '*.m'))\n",
    "    if not m_files:\n",
    "        raise FileNotFoundError(f\"No .m files found in {os.path.join(root,'Test')} for GT.\")\n",
    "    text = open(m_files[0], 'r').read()\n",
    "\n",
    "    # match lines like: TestVideoFile{end+1}.gt_frame = [61:180];\n",
    "    matches = re.findall(\n",
    "        r\"TestVideoFile\\{end\\+1\\}\\.gt_frame\\s*=\\s*\\[(\\d+):(\\d+)\\];\",\n",
    "        text\n",
    "    )\n",
    "    if not matches:\n",
    "        raise ValueError(\"No gt_frame definitions found in TestVideoFile .m file.\")\n",
    "\n",
    "    gt_list = []\n",
    "    for start_str, end_str in matches:\n",
    "        start, end = int(start_str), int(end_str)\n",
    "        # MATLAB ranges are inclusive\n",
    "        gt_list.append(list(range(start, end+1)))\n",
    "\n",
    "    return gt_list\n",
    "\n",
    "# 3. Combined Loss (MSE + L1 + MS-SSIM)\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, beta=0.3, gamma=0.2):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.l1 = nn.L1Loss()\n",
    "        self.alpha, self.beta, self.gamma = alpha, beta, gamma\n",
    "\n",
    "    def forward(self, recon, x):\n",
    "        loss_mse = self.mse(recon, x)\n",
    "        loss_l1 = self.l1(recon, x)\n",
    "        x01 = (x + 1) / 2\n",
    "        r01 = (recon + 1) / 2\n",
    "        ssim_val = ssim(r01, x01, data_range=1.0, size_average=True)\n",
    "        loss_ssim = 1 - ssim_val\n",
    "        return self.alpha * loss_mse + self.beta * loss_l1 + self.gamma * loss_ssim\n",
    "\n",
    "# 4. U-Net Autoencoder\n",
    "class UNetAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.enc1 = nn.Sequential(nn.Conv2d(1,32,3,1,1), nn.ReLU(True))\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.enc2 = nn.Sequential(nn.Conv2d(32,64,3,1,1), nn.ReLU(True))\n",
    "        self.enc3 = nn.Sequential(nn.Conv2d(64,128,3,1,1), nn.ReLU(True))\n",
    "        self.up23 = nn.ConvTranspose2d(128,64,2,2)\n",
    "        self.dec3 = nn.Sequential(nn.Conv2d(128,64,3,1,1), nn.ReLU(True))\n",
    "        self.up12 = nn.ConvTranspose2d(64,32,2,2)\n",
    "        self.dec2 = nn.Sequential(nn.Conv2d(64,32,3,1,1), nn.ReLU(True))\n",
    "        self.final = nn.Conv2d(32,1,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "        d3 = self.up23(e3)\n",
    "        d3 = torch.cat([d3,e2],1)\n",
    "        d3 = self.dec3(d3)\n",
    "        d2 = self.up12(d3)\n",
    "        d2 = torch.cat([d2,e1],1)\n",
    "        d2 = self.dec2(d2)\n",
    "        return torch.tanh(self.final(d2))\n",
    "\n",
    "# 5. Training loop\n",
    "def train_model(model, loader, epochs=50, lr=1e-3):\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=5)\n",
    "    criterion = CombinedLoss()\n",
    "    for ep in range(1,epochs+1):\n",
    "        model.train(); total_loss=0\n",
    "        for batch in loader:\n",
    "            x = batch[0] if isinstance(batch,(list,tuple)) else batch\n",
    "            x = x.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            recon = model(x)\n",
    "            loss = criterion(recon,x)\n",
    "            loss.backward(); optimizer.step()\n",
    "            total_loss += loss.item()*x.size(0)\n",
    "        avg_loss = total_loss/len(loader.dataset)\n",
    "        scheduler.step(avg_loss)\n",
    "        print(f\"Epoch {ep}/{epochs}, Loss={avg_loss:.6f}\")\n",
    "    return model\n",
    "\n",
    "# 6. Evaluation\n",
    "def evaluate(model,root,gt_list,bs=32):\n",
    "    model.eval()\n",
    "    ds = UCSDPed2Dataset(root, phase='testing', gt_list=gt_list)\n",
    "    loader = DataLoader(ds, batch_size=bs, shuffle=False)\n",
    "    scores, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            recon = model(x)\n",
    "            err = torch.mean((recon-x)**2,[1,2,3]).cpu().numpy()\n",
    "            scores.extend(err.tolist()); labels.extend(y)\n",
    "    auc = roc_auc_score(labels, scores)\n",
    "    fpr, tpr, th = roc_curve(labels, scores); thr = th[np.argmax(tpr-fpr)]\n",
    "    preds = [1 if s>=thr else 0 for s in scores]\n",
    "    cm = confusion_matrix(labels, preds); acc = accuracy_score(labels, preds); f1 = f1_score(labels, preds)\n",
    "    print(f\"AUC={auc:.4f},Acc={acc:.4f},F1={f1:.4f}\\nCM:\\n{cm}\")\n",
    "    print(classification_report(labels, preds, target_names=['Normal','Anomaly']))\n",
    "\n",
    "# 7. Main\n",
    "if __name__=='__main__':\n",
    "    root = '/l/users/zainab.aldhanhani/AI702Project/UCSD_Anomaly_Dataset.v1p2/UCSDped2'\n",
    "    gt_list = load_ucsd_gt(root)\n",
    "    train_ds = UCSDPed2Dataset(root, phase='training', gt_list=gt_list)\n",
    "    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=4)\n",
    "    model = UNetAutoencoder()\n",
    "    model = train_model(model, train_loader, epochs=50, lr=1e-3)\n",
    "    torch.save(model.state_dict(), 'ucsdped2_unet.pth')\n",
    "    evaluate(model, root, gt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MixUp & CutMix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss=0.105207\n",
      "Epoch 2/50, Loss=0.035627\n",
      "Epoch 3/50, Loss=0.025068\n",
      "Epoch 4/50, Loss=0.020006\n",
      "Epoch 5/50, Loss=0.017223\n",
      "Epoch 6/50, Loss=0.015360\n",
      "Epoch 7/50, Loss=0.014132\n",
      "Epoch 8/50, Loss=0.013182\n",
      "Epoch 9/50, Loss=0.012393\n",
      "Epoch 10/50, Loss=0.011693\n",
      "Epoch 11/50, Loss=0.011098\n",
      "Epoch 12/50, Loss=0.010590\n",
      "Epoch 13/50, Loss=0.010177\n",
      "Epoch 14/50, Loss=0.009877\n",
      "Epoch 15/50, Loss=0.009491\n",
      "Epoch 16/50, Loss=0.009207\n",
      "Epoch 17/50, Loss=0.008903\n",
      "Epoch 18/50, Loss=0.008740\n",
      "Epoch 19/50, Loss=0.008494\n",
      "Epoch 20/50, Loss=0.008327\n",
      "Epoch 21/50, Loss=0.008146\n",
      "Epoch 22/50, Loss=0.007997\n",
      "Epoch 23/50, Loss=0.007822\n",
      "Epoch 24/50, Loss=0.007703\n",
      "Epoch 25/50, Loss=0.007530\n",
      "Epoch 26/50, Loss=0.007424\n",
      "Epoch 27/50, Loss=0.007339\n",
      "Epoch 28/50, Loss=0.007231\n",
      "Epoch 29/50, Loss=0.007091\n",
      "Epoch 30/50, Loss=0.006998\n",
      "Epoch 31/50, Loss=0.006870\n",
      "Epoch 32/50, Loss=0.006820\n",
      "Epoch 33/50, Loss=0.006737\n",
      "Epoch 34/50, Loss=0.006564\n",
      "Epoch 35/50, Loss=0.006517\n",
      "Epoch 36/50, Loss=0.006374\n",
      "Epoch 37/50, Loss=0.006362\n",
      "Epoch 38/50, Loss=0.006271\n",
      "Epoch 39/50, Loss=0.006225\n",
      "Epoch 40/50, Loss=0.006121\n",
      "Epoch 41/50, Loss=0.006065\n",
      "Epoch 42/50, Loss=0.006009\n",
      "Epoch 43/50, Loss=0.005953\n",
      "Epoch 44/50, Loss=0.005845\n",
      "Epoch 45/50, Loss=0.005819\n",
      "Epoch 46/50, Loss=0.005804\n",
      "Epoch 47/50, Loss=0.005649\n",
      "Epoch 48/50, Loss=0.005672\n",
      "Epoch 49/50, Loss=0.005571\n",
      "Epoch 50/50, Loss=0.005508\n",
      "AUC=0.6710, Acc=0.7512, F1=0.8434\n",
      "CM:\n",
      "[[ 164  198]\n",
      " [ 302 1346]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.35      0.45      0.40       362\n",
      "     Anomaly       0.87      0.82      0.84      1648\n",
      "\n",
      "    accuracy                           0.75      2010\n",
      "   macro avg       0.61      0.63      0.62      2010\n",
      "weighted avg       0.78      0.75      0.76      2010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from pytorch_msssim import ssim  # pip install pytorch-msssim\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 0. MixUp and CutMix helper functions\n",
    "def mixup_data(x, alpha=1.0):\n",
    "    if alpha <= 0:\n",
    "        return x\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    return lam * x + (1 - lam) * x[index]\n",
    "\n",
    "\n",
    "def cutmix_data(x, alpha=1.0):\n",
    "    if alpha <= 0:\n",
    "        return x\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size, _, H, W = x.size()\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "    cx = random.randint(0, W)\n",
    "    cy = random.randint(0, H)\n",
    "    bbx1 = max(cx - cut_w // 2, 0)\n",
    "    bby1 = max(cy - cut_h // 2, 0)\n",
    "    bbx2 = min(cx + cut_w // 2, W)\n",
    "    bby2 = min(cy + cut_h // 2, H)\n",
    "    x_cutmix = x.clone()\n",
    "    x_cutmix[:, :, bby1:bby2, bbx1:bbx2] = x[index, :, bby1:bby2, bbx1:bbx2]\n",
    "    return x_cutmix\n",
    "\n",
    "# 1. Dataset loader for UCSD Ped2\n",
    "default_transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "class UCSDPed2Dataset(Dataset):\n",
    "    def __init__(self, root, phase='training', transform=None, gt_list=None):\n",
    "        self.phase = phase\n",
    "        self.transform = transform or default_transform\n",
    "        subdir = 'Train' if phase == 'training' else 'Test'\n",
    "        base_dir = os.path.join(root, subdir)\n",
    "        vids = sorted([d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))])\n",
    "        self.paths = []\n",
    "        self.labels = []\n",
    "        for vid in vids:\n",
    "            frame_dir = os.path.join(base_dir, vid)\n",
    "            for ext in ('*.png', '*.jpg', '*.jpeg', '*.tif'):\n",
    "                for p in sorted(glob.glob(os.path.join(frame_dir, ext))):\n",
    "                    self.paths.append(p)\n",
    "                    if phase == 'testing' and gt_list is not None:\n",
    "                        frame_idx = int(os.path.splitext(os.path.basename(p))[0])\n",
    "                        vid_idx = int(re.sub('[^0-9]', '', vid)) - 1\n",
    "                        self.labels.append(1 if frame_idx in gt_list[vid_idx] else 0)\n",
    "                    else:\n",
    "                        self.labels.append(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.paths[idx]).convert('L')\n",
    "        x = self.transform(img)\n",
    "        return (x, self.labels[idx]) if self.phase == 'testing' else x\n",
    "\n",
    "# 2. Load ground truth from .m file in Test folder\n",
    "def load_ucsd_gt(root):\n",
    "    test_dir = os.path.join(root, 'Test')\n",
    "    m_files = glob.glob(os.path.join(test_dir, '*.m'))\n",
    "    if not m_files:\n",
    "        raise FileNotFoundError(f\"No .m files found in {test_dir} for GT.\")\n",
    "    text = open(m_files[0], 'r').read()\n",
    "    # parse lines: TestVideoFile{end+1}.gt_frame = [start:end];\n",
    "    matches = re.findall(r\"TestVideoFile\\{end\\+1\\}\\.gt_frame\\s*=\\s*\\[(\\d+):(\\d+)\\];\", text)\n",
    "    if not matches:\n",
    "        raise ValueError(\"No gt_frame definitions in TestVideoFile .m file.\")\n",
    "    gt_list = []\n",
    "    for s_str, e_str in matches:\n",
    "        s, e = int(s_str), int(e_str)\n",
    "        gt_list.append(list(range(s, e+1)))\n",
    "    return gt_list\n",
    "\n",
    "# 3. Combined Loss (MSE + L1 + MS-SSIM)\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, beta=0.3, gamma=0.2):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.l1 = nn.L1Loss()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, recon, x):\n",
    "        loss_mse = self.mse(recon, x)\n",
    "        loss_l1 = self.l1(recon, x)\n",
    "        x01 = (x + 1) / 2\n",
    "        r01 = (recon + 1) / 2\n",
    "        ssim_val = ssim(r01, x01, data_range=1.0, size_average=True)\n",
    "        loss_ssim = 1 - ssim_val\n",
    "        return self.alpha * loss_mse + self.beta * loss_l1 + self.gamma * loss_ssim\n",
    "\n",
    "# 4. Simplified Autoencoder\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 2, 1), nn.ReLU(True),  # 128->64\n",
    "            nn.Conv2d(32, 64, 3, 2, 1), nn.ReLU(True),  # 64->32\n",
    "            nn.Conv2d(64,128, 3, 2, 1), nn.ReLU(True)   # 32->16\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128,64,3,2,1,1), nn.ReLU(True),  # 16->32\n",
    "            nn.ConvTranspose2d(64,32,3,2,1,1), nn.ReLU(True),   # 32->64\n",
    "            nn.ConvTranspose2d(32, 1,3,2,1,1), nn.Tanh()        # 64->128\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)\n",
    "\n",
    "# 5. Trainer with MixUp & CutMix\n",
    "class Trainer:\n",
    "    def __init__(self, model, loader, lr=1e-3):\n",
    "        self.model = model.to(device)\n",
    "        self.loader = loader\n",
    "        self.opt = optim.Adam(model.parameters(), lr=lr)\n",
    "        self.sched = optim.lr_scheduler.ReduceLROnPlateau(self.opt, 'min', factor=0.5, patience=5)\n",
    "        self.crit = CombinedLoss()\n",
    "\n",
    "    def train(self, epochs=50, mixup_alpha=0.4, cutmix_alpha=0.4, mix_prob=0.5):\n",
    "        for ep in range(1, epochs + 1):\n",
    "            self.model.train()\n",
    "            running_loss = 0.0\n",
    "            for batch in self.loader:\n",
    "                # handle either (x, labels) or x-only batches\n",
    "                if isinstance(batch, (list, tuple)):\n",
    "                    x = batch[0].to(device)\n",
    "                else:\n",
    "                    x = batch.to(device)\n",
    "                # apply MixUp or CutMix randomly\n",
    "                if random.random() < mix_prob:\n",
    "                    if random.random() < 0.5:\n",
    "                        x = mixup_data(x, mixup_alpha)\n",
    "                    else:\n",
    "                        x = cutmix_data(x, cutmix_alpha)\n",
    "                self.opt.zero_grad()\n",
    "                recon = self.model(x)\n",
    "                loss = self.crit(recon, x)\n",
    "                loss.backward()\n",
    "                self.opt.step()\n",
    "                running_loss += loss.item() * x.size(0)\n",
    "            avg_loss = running_loss / len(self.loader.dataset)\n",
    "            self.sched.step(avg_loss)\n",
    "            print(f\"Epoch {ep}/{epochs}, Loss={avg_loss:.6f}\")\n",
    "        return self.model\n",
    "\n",
    "# 6. Evaluation Evaluation\n",
    "def evaluate(model, root, gt_list, bs=32):\n",
    "    model.eval()\n",
    "    ds = UCSDPed2Dataset(root, phase='testing', gt_list=gt_list)\n",
    "    loader = DataLoader(ds, batch_size=bs, shuffle=False)\n",
    "    scores, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            recon = model(x)\n",
    "            err = torch.mean((recon - x)**2, dim=[1,2,3]).cpu().numpy()\n",
    "            scores.extend(err.tolist())\n",
    "            labels.extend(y)\n",
    "    auc = roc_auc_score(labels, scores)\n",
    "    fpr, tpr, th = roc_curve(labels, scores)\n",
    "    thr = th[np.argmax(tpr - fpr)]\n",
    "    preds = [1 if s >= thr else 0 for s in scores]\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    print(f\"AUC={auc:.4f}, Acc={acc:.4f}, F1={f1:.4f}\\nCM:\\n{cm}\")\n",
    "    print(classification_report(labels, preds, target_names=['Normal','Anomaly']))\n",
    "\n",
    "# 7. Main\n",
    "if __name__ == '__main__':\n",
    "    root = '/l/users/zainab.aldhanhani/AI702Project/UCSD_Anomaly_Dataset.v1p2/UCSDped2'\n",
    "    gt_list = load_ucsd_gt(root)\n",
    "    train_ds = UCSDPed2Dataset(root, phase='training', gt_list=gt_list)\n",
    "    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=4)\n",
    "    model = Autoencoder()\n",
    "    trainer = Trainer(model, train_loader)\n",
    "    model = trainer.train(epochs=50, mixup_alpha=0.4, cutmix_alpha=0.4, mix_prob=0.5)\n",
    "    torch.save(model.state_dict(), 'ucsdped2_auto_mix.pth')\n",
    "    evaluate(model, root, gt_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environmental Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss=0.105661\n",
      "Epoch 2/50, Loss=0.039038\n",
      "Epoch 3/50, Loss=0.028453\n",
      "Epoch 4/50, Loss=0.022394\n",
      "Epoch 5/50, Loss=0.019367\n",
      "Epoch 6/50, Loss=0.016954\n",
      "Epoch 7/50, Loss=0.015717\n",
      "Epoch 8/50, Loss=0.014761\n",
      "Epoch 9/50, Loss=0.013638\n",
      "Epoch 10/50, Loss=0.013035\n",
      "Epoch 11/50, Loss=0.012304\n",
      "Epoch 12/50, Loss=0.011732\n",
      "Epoch 13/50, Loss=0.011364\n",
      "Epoch 14/50, Loss=0.011076\n",
      "Epoch 15/50, Loss=0.010593\n",
      "Epoch 16/50, Loss=0.010209\n",
      "Epoch 17/50, Loss=0.010389\n",
      "Epoch 18/50, Loss=0.009942\n",
      "Epoch 19/50, Loss=0.009174\n",
      "Epoch 20/50, Loss=0.008878\n",
      "Epoch 21/50, Loss=0.008653\n",
      "Epoch 22/50, Loss=0.008568\n",
      "Epoch 23/50, Loss=0.008631\n",
      "Epoch 24/50, Loss=0.008064\n",
      "Epoch 25/50, Loss=0.008099\n",
      "Epoch 26/50, Loss=0.008101\n",
      "Epoch 27/50, Loss=0.008128\n",
      "Epoch 28/50, Loss=0.007572\n",
      "Epoch 29/50, Loss=0.007519\n",
      "Epoch 30/50, Loss=0.007783\n",
      "Epoch 31/50, Loss=0.007144\n",
      "Epoch 32/50, Loss=0.007166\n",
      "Epoch 33/50, Loss=0.007133\n",
      "Epoch 34/50, Loss=0.006870\n",
      "Epoch 35/50, Loss=0.006886\n",
      "Epoch 36/50, Loss=0.007060\n",
      "Epoch 37/50, Loss=0.006743\n",
      "Epoch 38/50, Loss=0.006678\n",
      "Epoch 39/50, Loss=0.006500\n",
      "Epoch 40/50, Loss=0.006480\n",
      "Epoch 41/50, Loss=0.006762\n",
      "Epoch 42/50, Loss=0.007170\n",
      "Epoch 43/50, Loss=0.006570\n",
      "Epoch 44/50, Loss=0.006048\n",
      "Epoch 45/50, Loss=0.006133\n",
      "Epoch 46/50, Loss=0.005977\n",
      "Epoch 47/50, Loss=0.006454\n",
      "Epoch 48/50, Loss=0.006327\n",
      "Epoch 49/50, Loss=0.005814\n",
      "Epoch 50/50, Loss=0.005729\n",
      "AUC=0.6480, Acc=0.7930, F1=0.8752CM:[[ 135  227]\n",
      " [ 189 1459]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.42      0.37      0.39       362\n",
      "     Anomaly       0.87      0.89      0.88      1648\n",
      "\n",
      "    accuracy                           0.79      2010\n",
      "   macro avg       0.64      0.63      0.63      2010\n",
      "weighted avg       0.78      0.79      0.79      2010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFilter, ImageEnhance\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from pytorch_msssim import ssim  # pip install pytorch-msssim\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Simulated Environmental Effects augmentation\n",
    "class EnvironmentalTransform:\n",
    "    def __init__(self, rain_prob=0.3, fog_prob=0.3, sun_prob=0.3):\n",
    "        self.rain_prob = rain_prob\n",
    "        self.fog_prob = fog_prob\n",
    "        self.sun_prob = sun_prob\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Rain effect\n",
    "        if random.random() < self.rain_prob:\n",
    "            img = self._add_rain(img)\n",
    "        # Fog effect\n",
    "        if random.random() < self.fog_prob:\n",
    "            img = self._add_fog(img)\n",
    "        # Sun glare\n",
    "        if random.random() < self.sun_prob:\n",
    "            img = self._add_sun_glare(img)\n",
    "        return img\n",
    "\n",
    "    def _add_rain(self, img: Image.Image) -> Image.Image:\n",
    "        arr = np.array(img)\n",
    "        h, w = arr.shape\n",
    "        rain = np.zeros((h, w), dtype=np.uint8)\n",
    "        drops = int(h * w * 0.0005)\n",
    "        for _ in range(drops):\n",
    "            x = random.randint(0, w-1)\n",
    "            y = random.randint(0, h-1)\n",
    "            length = random.randint(10, 20)\n",
    "            for i in range(length):\n",
    "                yy = min(h-1, y+i)\n",
    "                rain[yy, x] = 255\n",
    "        rain_img = Image.fromarray(rain).filter(ImageFilter.GaussianBlur(1))\n",
    "        return Image.blend(img, rain_img, alpha=0.3)\n",
    "\n",
    "    def _add_fog(self, img: Image.Image) -> Image.Image:\n",
    "        fog = Image.new('L', img.size, color=255)\n",
    "        fog = fog.filter(ImageFilter.GaussianBlur(radius=img.size[0]//15))\n",
    "        return Image.blend(img, fog, alpha=0.4)\n",
    "\n",
    "    def _add_sun_glare(self, img: Image.Image) -> Image.Image:\n",
    "        w, h = img.size\n",
    "        mask = Image.new('L', (w, h), 0)\n",
    "        cx, cy = random.randint(w//4, 3*w//4), random.randint(h//4, 3*h//4)\n",
    "        rad = random.randint(min(w,h)//8, min(w,h)//4)\n",
    "        yy, xx = np.ogrid[:h, :w]\n",
    "        circle = ((xx-cx)**2 + (yy-cy)**2) <= rad**2\n",
    "        mask_arr = np.zeros((h, w), dtype=np.uint8)\n",
    "        mask_arr[circle] = 255\n",
    "        mask = Image.fromarray(mask_arr)\n",
    "        bright = ImageEnhance.Brightness(img).enhance(1.5)\n",
    "        return Image.composite(bright, img, mask)\n",
    "\n",
    "# 1. Dataset loader for UCSD Ped2\n",
    "train_transform = transforms.Compose([\n",
    "    EnvironmentalTransform(rain_prob=0.3, fog_prob=0.3, sun_prob=0.3),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "class UCSDPed2Dataset(Dataset):\n",
    "    def __init__(self, root, phase='training', transform=None, gt_list=None):\n",
    "        self.phase = phase\n",
    "        self.transform = transform\n",
    "        subdir = 'Train' if phase == 'training' else 'Test'\n",
    "        base_dir = os.path.join(root, subdir)\n",
    "        vids = sorted([d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))])\n",
    "        self.paths, self.labels = [], []\n",
    "        for vid in vids:\n",
    "            frame_dir = os.path.join(base_dir, vid)\n",
    "            for ext in ('*.png','*.jpg','*.jpeg','*.tif'):\n",
    "                for p in sorted(glob.glob(os.path.join(frame_dir, ext))):\n",
    "                    self.paths.append(p)\n",
    "                    if phase=='testing' and gt_list is not None:\n",
    "                        idx = int(os.path.splitext(os.path.basename(p))[0])\n",
    "                        vid_idx = int(re.sub('[^0-9]','',vid)) - 1\n",
    "                        self.labels.append(1 if idx in gt_list[vid_idx] else 0)\n",
    "                    else:\n",
    "                        self.labels.append(0)\n",
    "\n",
    "    def __len__(self): return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.paths[idx]).convert('L')\n",
    "        x = self.transform(img)\n",
    "        return (x, self.labels[idx]) if self.phase=='testing' else x\n",
    "\n",
    "# 2. Load ground truth\n",
    "import glob, re\n",
    "\n",
    "def load_ucsd_gt(root):\n",
    "    m_files = glob.glob(os.path.join(root,'Test','*.m'))\n",
    "    if not m_files:\n",
    "        raise FileNotFoundError(f\"No .m GT files in {root}/Test\")\n",
    "    text = open(m_files[0],'r').read()\n",
    "    matches = re.findall(r\"TestVideoFile\\{end\\+1\\}\\.gt_frame\\s*=\\s*\\[(\\d+):(\\d+)\\];\", text)\n",
    "    if not matches: raise ValueError(\"No gt_frame lines found.\")\n",
    "    return [list(range(int(s),int(e)+1)) for s,e in matches]\n",
    "\n",
    "# 3. Combined Loss (MSE + L1 + MS-SSIM)\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5,beta=0.3,gamma=0.2):\n",
    "        super().__init__()\n",
    "        self.mse=nn.MSELoss(); self.l1=nn.L1Loss()\n",
    "        self.alpha, self.beta, self.gamma = alpha,beta,gamma\n",
    "    def forward(self,recon,x):\n",
    "        m=self.mse(recon,x); l=self.l1(recon,x)\n",
    "        x01=(x+1)/2; r01=(recon+1)/2\n",
    "        s=ssim(r01,x01,data_range=1.0,size_average=True)\n",
    "        return self.alpha*m + self.beta*l + self.gamma*(1-s)\n",
    "\n",
    "# 4. Simplified Autoencoder\n",
    "def conv_autoencoder():\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(1,32,3,2,1), nn.ReLU(True),\n",
    "        nn.Conv2d(32,64,3,2,1), nn.ReLU(True),\n",
    "        nn.Conv2d(64,128,3,2,1), nn.ReLU(True),\n",
    "        nn.ConvTranspose2d(128,64,3,2,1,1), nn.ReLU(True),\n",
    "        nn.ConvTranspose2d(64,32,3,2,1,1), nn.ReLU(True),\n",
    "        nn.ConvTranspose2d(32,1,3,2,1,1), nn.Tanh()\n",
    "    )\n",
    "\n",
    "# 5. Training loop\n",
    "    \n",
    "def train_model(model, loader, epochs=50, lr=1e-3):\n",
    "    model.to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "    sched = optim.lr_scheduler.ReduceLROnPlateau(opt, 'min', factor=0.5, patience=5)\n",
    "    crit = CombinedLoss()\n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train()\n",
    "        tot_loss = 0.0\n",
    "        for batch in loader:\n",
    "            # batch may be (x, labels) or just x\n",
    "            if isinstance(batch, (list, tuple)):\n",
    "                x = batch[0].to(device)\n",
    "            else:\n",
    "                x = batch.to(device)\n",
    "            opt.zero_grad()\n",
    "            recon = model(x)\n",
    "            loss = crit(recon, x)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            tot_loss += loss.item() * x.size(0)\n",
    "        avg_loss = tot_loss / len(loader.dataset)\n",
    "        sched.step(avg_loss)\n",
    "        print(f\"Epoch {ep}/{epochs}, Loss={avg_loss:.6f}\")\n",
    "    return model\n",
    "\n",
    "# 6. Evaluation\n",
    "def evaluate(model, root, gt_list, bs=32):\n",
    "    model.eval()\n",
    "    scores, labels = [], []\n",
    "    ds = UCSDPed2Dataset(root, 'testing', test_transform, gt_list)\n",
    "    loader = DataLoader(ds, batch_size=bs, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            recon = model(x)\n",
    "            err = torch.mean((recon - x) ** 2, dim=[1, 2, 3]).cpu().numpy()\n",
    "            scores.extend(err.tolist())\n",
    "            labels.extend(y)\n",
    "    auc = roc_auc_score(labels, scores)\n",
    "    fpr, tpr, th = roc_curve(labels, scores)\n",
    "    thr = th[np.argmax(tpr - fpr)]\n",
    "    preds = [1 if s >= thr else 0 for s in scores]\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    print(f\"AUC={auc:.4f}, Acc={acc:.4f}, F1={f1:.4f}CM:{cm}\")\n",
    "    print(classification_report(labels, preds, target_names=['Normal', 'Anomaly']))\n",
    "\n",
    "# 7. Main\n",
    "if __name__=='__main__':\n",
    "    root='/l/users/zainab.aldhanhani/AI702Project/UCSD_Anomaly_Dataset.v1p2/UCSDped2'\n",
    "    gt_list=load_ucsd_gt(root)\n",
    "    train_ds=UCSDPed2Dataset(root,'training',train_transform,gt_list)\n",
    "    train_loader=DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=4)\n",
    "    model=conv_autoencoder()\n",
    "    model=train_model(model,train_loader,50,1e-3)\n",
    "    torch.save(model.state_dict(),'ucsdped2_env.pth')\n",
    "    evaluate(model,root,gt_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier Domain Adaptation (FDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss=0.115845\n",
      "Epoch 2/50, Loss=0.037415\n",
      "Epoch 3/50, Loss=0.025830\n",
      "Epoch 4/50, Loss=0.020191\n",
      "Epoch 5/50, Loss=0.017085\n",
      "Epoch 6/50, Loss=0.015104\n",
      "Epoch 7/50, Loss=0.013727\n",
      "Epoch 8/50, Loss=0.012617\n",
      "Epoch 9/50, Loss=0.011819\n",
      "Epoch 10/50, Loss=0.011089\n",
      "Epoch 11/50, Loss=0.010527\n",
      "Epoch 12/50, Loss=0.010028\n",
      "Epoch 13/50, Loss=0.009564\n",
      "Epoch 14/50, Loss=0.009183\n",
      "Epoch 15/50, Loss=0.008866\n",
      "Epoch 16/50, Loss=0.008573\n",
      "Epoch 17/50, Loss=0.008329\n",
      "Epoch 18/50, Loss=0.008060\n",
      "Epoch 19/50, Loss=0.007871\n",
      "Epoch 20/50, Loss=0.007710\n",
      "Epoch 21/50, Loss=0.007511\n",
      "Epoch 22/50, Loss=0.007369\n",
      "Epoch 23/50, Loss=0.007209\n",
      "Epoch 24/50, Loss=0.007106\n",
      "Epoch 25/50, Loss=0.006949\n",
      "Epoch 26/50, Loss=0.006821\n",
      "Epoch 27/50, Loss=0.006764\n",
      "Epoch 28/50, Loss=0.006629\n",
      "Epoch 29/50, Loss=0.006533\n",
      "Epoch 30/50, Loss=0.006425\n",
      "Epoch 31/50, Loss=0.006306\n",
      "Epoch 32/50, Loss=0.006280\n",
      "Epoch 33/50, Loss=0.006192\n",
      "Epoch 34/50, Loss=0.006078\n",
      "Epoch 35/50, Loss=0.006023\n",
      "Epoch 36/50, Loss=0.005922\n",
      "Epoch 37/50, Loss=0.005877\n",
      "Epoch 38/50, Loss=0.005817\n",
      "Epoch 39/50, Loss=0.005708\n",
      "Epoch 40/50, Loss=0.005716\n",
      "Epoch 41/50, Loss=0.005626\n",
      "Epoch 42/50, Loss=0.005525\n",
      "Epoch 43/50, Loss=0.005542\n",
      "Epoch 44/50, Loss=0.005468\n",
      "Epoch 45/50, Loss=0.005353\n",
      "Epoch 46/50, Loss=0.005359\n",
      "Epoch 47/50, Loss=0.005325\n",
      "Epoch 48/50, Loss=0.005276\n",
      "Epoch 49/50, Loss=0.005178\n",
      "Epoch 50/50, Loss=0.005130\n",
      "AUC=0.6669, Acc=0.7776, F1=0.8646\n",
      "CM:\n",
      "[[ 136  226]\n",
      " [ 221 1427]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.38      0.38      0.38       362\n",
      "     Anomaly       0.86      0.87      0.86      1648\n",
      "\n",
      "    accuracy                           0.78      2010\n",
      "   macro avg       0.62      0.62      0.62      2010\n",
      "weighted avg       0.78      0.78      0.78      2010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from pytorch_msssim import ssim  # pip install pytorch-msssim\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Fourier Domain Adaptation augmentation\n",
    "class FDATransform:\n",
    "    def __init__(self, root, patch_ratio=0.1, probability=0.5):\n",
    "        self.probability = probability\n",
    "        self.patch_ratio = patch_ratio\n",
    "        base = os.path.join(root, 'Train')\n",
    "        self.img_paths = []\n",
    "        vids = sorted(d for d in os.listdir(base) if os.path.isdir(os.path.join(base, d)))\n",
    "        for vid in vids:\n",
    "            frame_dir = os.path.join(base, vid)\n",
    "            for ext in ('*.png','*.jpg','*.jpeg','*.tif'):\n",
    "                self.img_paths += glob.glob(os.path.join(frame_dir, ext))\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() > self.probability or not self.img_paths:\n",
    "            return img\n",
    "        tgt = np.array(img).astype(np.float32)\n",
    "        src_path = random.choice(self.img_paths)\n",
    "        src = Image.open(src_path).convert('L').resize(img.size)\n",
    "        src = np.array(src).astype(np.float32)\n",
    "        fft_tgt = np.fft.fft2(tgt)\n",
    "        fft_src = np.fft.fft2(src)\n",
    "        amp_tgt, pha_tgt = np.abs(fft_tgt), np.angle(fft_tgt)\n",
    "        amp_src = np.abs(fft_src)\n",
    "        h, w = tgt.shape\n",
    "        b = int(min(h, w) * self.patch_ratio)\n",
    "        cy, cx = h//2, w//2\n",
    "        amp_tgt[cy-b:cy+b, cx-b:cx+b] = amp_src[cy-b:cy+b, cx-b:cx+b]\n",
    "        fft_new = amp_tgt * np.exp(1j * pha_tgt)\n",
    "        img_back = np.fft.ifft2(fft_new)\n",
    "        img_back = np.real(img_back)\n",
    "        img_back = np.clip(img_back, 0, 255).astype(np.uint8)\n",
    "        return Image.fromarray(img_back)\n",
    "\n",
    "# Dataset loader for UCSD Ped2\n",
    "class UCSDPed2Dataset(Dataset):\n",
    "    def __init__(self, root, phase='training', transform=None, gt_list=None):\n",
    "        self.phase = phase\n",
    "        self.transform = transform\n",
    "        subdir = 'Train' if phase=='training' else 'Test'\n",
    "        base_dir = os.path.join(root, subdir)\n",
    "        vids = sorted(d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d)))\n",
    "        self.paths, self.labels = [], []\n",
    "        for vid in vids:\n",
    "            frame_dir = os.path.join(base_dir, vid)\n",
    "            for ext in ('*.png','*.jpg','*.jpeg','*.tif'):\n",
    "                for p in sorted(glob.glob(os.path.join(frame_dir, ext))):\n",
    "                    self.paths.append(p)\n",
    "                    if phase=='testing' and gt_list is not None:\n",
    "                        idx = int(os.path.splitext(os.path.basename(p))[0])\n",
    "                        vid_idx = int(re.sub('[^0-9]','',vid)) - 1\n",
    "                        self.labels.append(1 if idx in gt_list[vid_idx] else 0)\n",
    "                    else:\n",
    "                        self.labels.append(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.paths[idx]).convert('L')\n",
    "        x = self.transform(img)\n",
    "        return (x, self.labels[idx]) if self.phase=='testing' else x\n",
    "\n",
    "# Ground truth loader from .m file\n",
    "def load_ucsd_gt(root):\n",
    "    m_files = glob.glob(os.path.join(root, 'Test', '*.m'))\n",
    "    if not m_files:\n",
    "        raise FileNotFoundError(f\"No .m GT files in {os.path.join(root,'Test')}\")\n",
    "    text = open(m_files[0],'r').read()\n",
    "    matches = re.findall(r\"TestVideoFile\\{end\\+1\\}\\.gt_frame\\s*=\\s*\\[(\\d+):(\\d+)\\];\", text)\n",
    "    if not matches:\n",
    "        raise ValueError(\"No gt_frame lines found in .m file.\")\n",
    "    return [list(range(int(s), int(e)+1)) for s, e in matches]\n",
    "\n",
    "# Combined Loss (MSE + L1 + MS-SSIM)\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, beta=0.3, gamma=0.2):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.l1 = nn.L1Loss()\n",
    "        self.alpha, self.beta, self.gamma = alpha, beta, gamma\n",
    "    def forward(self, recon, x):\n",
    "        m = self.mse(recon, x)\n",
    "        l = self.l1(recon, x)\n",
    "        x01 = (x + 1) / 2\n",
    "        r01 = (recon + 1) / 2\n",
    "        s = ssim(r01, x01, data_range=1.0, size_average=True)\n",
    "        return self.alpha * m + self.beta * l + self.gamma * (1 - s)\n",
    "\n",
    "# Simplified convolutional autoencoder\n",
    "def conv_autoencoder():\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(1,32,3,2,1), nn.ReLU(True),\n",
    "        nn.Conv2d(32,64,3,2,1), nn.ReLU(True),\n",
    "        nn.Conv2d(64,128,3,2,1), nn.ReLU(True),\n",
    "        nn.ConvTranspose2d(128,64,3,2,1,1), nn.ReLU(True),\n",
    "        nn.ConvTranspose2d(64,32,3,2,1,1), nn.ReLU(True),\n",
    "        nn.ConvTranspose2d(32,1,3,2,1,1), nn.Tanh()\n",
    "    )\n",
    "\n",
    "# Training loop\n",
    "def train_model(model, loader, epochs=50, lr=1e-3):\n",
    "    model.to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "    sched = optim.lr_scheduler.ReduceLROnPlateau(opt, 'min', factor=0.5, patience=5)\n",
    "    crit = CombinedLoss()\n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train()\n",
    "        tot = 0\n",
    "        for batch in loader:\n",
    "            x = batch[0].to(device) if isinstance(batch, (list, tuple)) else batch.to(device)\n",
    "            opt.zero_grad()\n",
    "            recon = model(x)\n",
    "            loss = crit(recon, x)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            tot += loss.item() * x.size(0)\n",
    "        avg = tot / len(loader.dataset)\n",
    "        sched.step(avg)\n",
    "        print(f\"Epoch {ep}/{epochs}, Loss={avg:.6f}\")\n",
    "    return model\n",
    "\n",
    "# Evaluation\n",
    "def evaluate(model, root, gt_list, bs=32):\n",
    "    model.eval()\n",
    "    scores, labels = [], []\n",
    "    ds = UCSDPed2Dataset(root, 'testing', transform=test_transform, gt_list=gt_list)\n",
    "    loader = DataLoader(ds, batch_size=bs, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            recon = model(x)\n",
    "            err = torch.mean((recon - x)**2, dim=[1,2,3]).cpu().numpy()\n",
    "            scores.extend(err.tolist())\n",
    "            labels.extend(y)\n",
    "    auc = roc_auc_score(labels, scores)\n",
    "    fpr, tpr, th = roc_curve(labels, scores)\n",
    "    thr = th[np.argmax(tpr - fpr)]\n",
    "    preds = [1 if s >= thr else 0 for s in scores]\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    print(f\"AUC={auc:.4f}, Acc={accuracy_score(labels,preds):.4f}, F1={f1_score(labels,preds):.4f}\\nCM:\\n{cm}\")\n",
    "    print(classification_report(labels, preds, target_names=['Normal','Anomaly']))\n",
    "\n",
    "# Main\n",
    "if __name__ == '__main__':\n",
    "    root = '/l/users/zainab.aldhanhani/AI702Project/UCSD_Anomaly_Dataset.v1p2/UCSDped2'\n",
    "    # define transforms with FDA\n",
    "    train_transform = transforms.Compose([\n",
    "        FDATransform(root, patch_ratio=0.1, probability=0.5),\n",
    "        transforms.Grayscale(),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Grayscale(),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    gt_list = load_ucsd_gt(root)\n",
    "    train_ds = UCSDPed2Dataset(root, 'training', transform=train_transform, gt_list=gt_list)\n",
    "    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=4)\n",
    "    model = conv_autoencoder()\n",
    "    model = train_model(model, train_loader, epochs=50, lr=1e-3)\n",
    "    torch.save(model.state_dict(), 'ucsdped2_fda.pth')\n",
    "    evaluate(model, root, gt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Deformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss=0.111221\n",
      "Epoch 2/50, Loss=0.036086\n",
      "Epoch 3/50, Loss=0.025693\n",
      "Epoch 4/50, Loss=0.020824\n",
      "Epoch 5/50, Loss=0.018145\n",
      "Epoch 6/50, Loss=0.016509\n",
      "Epoch 7/50, Loss=0.015372\n",
      "Epoch 8/50, Loss=0.014418\n",
      "Epoch 9/50, Loss=0.013668\n",
      "Epoch 10/50, Loss=0.013058\n",
      "Epoch 11/50, Loss=0.012447\n",
      "Epoch 12/50, Loss=0.011904\n",
      "Epoch 13/50, Loss=0.011509\n",
      "Epoch 14/50, Loss=0.011074\n",
      "Epoch 15/50, Loss=0.010772\n",
      "Epoch 16/50, Loss=0.010455\n",
      "Epoch 17/50, Loss=0.010122\n",
      "Epoch 18/50, Loss=0.009842\n",
      "Epoch 19/50, Loss=0.009610\n",
      "Epoch 20/50, Loss=0.009402\n",
      "Epoch 21/50, Loss=0.009154\n",
      "Epoch 22/50, Loss=0.008947\n",
      "Epoch 23/50, Loss=0.008751\n",
      "Epoch 24/50, Loss=0.008621\n",
      "Epoch 25/50, Loss=0.008398\n",
      "Epoch 26/50, Loss=0.008306\n",
      "Epoch 27/50, Loss=0.008139\n",
      "Epoch 28/50, Loss=0.007972\n",
      "Epoch 29/50, Loss=0.007860\n",
      "Epoch 30/50, Loss=0.007760\n",
      "Epoch 31/50, Loss=0.007622\n",
      "Epoch 32/50, Loss=0.007490\n",
      "Epoch 33/50, Loss=0.007439\n",
      "Epoch 34/50, Loss=0.007331\n",
      "Epoch 35/50, Loss=0.007261\n",
      "Epoch 36/50, Loss=0.007160\n",
      "Epoch 37/50, Loss=0.007031\n",
      "Epoch 38/50, Loss=0.006941\n",
      "Epoch 39/50, Loss=0.006909\n",
      "Epoch 40/50, Loss=0.006801\n",
      "Epoch 41/50, Loss=0.006712\n",
      "Epoch 42/50, Loss=0.006630\n",
      "Epoch 43/50, Loss=0.006538\n",
      "Epoch 44/50, Loss=0.006439\n",
      "Epoch 45/50, Loss=0.006401\n",
      "Epoch 46/50, Loss=0.006304\n",
      "Epoch 47/50, Loss=0.006249\n",
      "Epoch 48/50, Loss=0.006167\n",
      "Epoch 49/50, Loss=0.006141\n",
      "Epoch 50/50, Loss=0.006069\n",
      "AUC=0.6611, Acc=0.7751, F1=0.8609\n",
      "CM:\n",
      "[[ 159  203]\n",
      " [ 249 1399]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.39      0.44      0.41       362\n",
      "     Anomaly       0.87      0.85      0.86      1648\n",
      "\n",
      "    accuracy                           0.78      2010\n",
      "   macro avg       0.63      0.64      0.64      2010\n",
      "weighted avg       0.79      0.78      0.78      2010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndi\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from pytorch_msssim import ssim  # pip install pytorch-msssim\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Elastic deformation augmentation\n",
    "class ElasticTransform:\n",
    "    def __init__(self, alpha=34, sigma=4, probability=0.5):\n",
    "        self.alpha = alpha\n",
    "        self.sigma = sigma\n",
    "        self.probability = probability\n",
    "\n",
    "    def __call__(self, img: Image.Image) -> Image.Image:\n",
    "        if random.random() > self.probability:\n",
    "            return img\n",
    "        arr = np.array(img)\n",
    "        shape = arr.shape\n",
    "        dx = ndi.gaussian_filter((np.random.rand(*shape) * 2 - 1), self.sigma) * self.alpha\n",
    "        dy = ndi.gaussian_filter((np.random.rand(*shape) * 2 - 1), self.sigma) * self.alpha\n",
    "        x, y = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]))\n",
    "        indices = (np.reshape(y + dy, (-1,)), np.reshape(x + dx, (-1,)))\n",
    "        distorted = ndi.map_coordinates(arr, indices, order=1, mode='reflect').reshape(shape)\n",
    "        return Image.fromarray(distorted.astype(np.uint8))\n",
    "\n",
    "# Dataset loader for UCSD Ped2\n",
    "class UCSDPed2Dataset(Dataset):\n",
    "    def __init__(self, root, phase='training', transform=None, gt_list=None):\n",
    "        self.phase = phase\n",
    "        self.transform = transform\n",
    "        subdir = 'Train' if phase == 'training' else 'Test'\n",
    "        base_dir = os.path.join(root, subdir)\n",
    "        vids = sorted(d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d)))\n",
    "        self.paths, self.labels = [], []\n",
    "        for vid in vids:\n",
    "            frame_dir = os.path.join(base_dir, vid)\n",
    "            for ext in ('*.png', '*.jpg', '*.jpeg', '*.tif'):\n",
    "                for p in sorted(glob.glob(os.path.join(frame_dir, ext))):\n",
    "                    self.paths.append(p)\n",
    "                    if phase == 'testing' and gt_list is not None:\n",
    "                        idx = int(os.path.splitext(os.path.basename(p))[0])\n",
    "                        vid_idx = int(re.sub('[^0-9]', '', vid)) - 1\n",
    "                        self.labels.append(1 if idx in gt_list[vid_idx] else 0)\n",
    "                    else:\n",
    "                        self.labels.append(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.paths[idx]).convert('L')\n",
    "        x = self.transform(img)\n",
    "        return (x, self.labels[idx]) if self.phase == 'testing' else x\n",
    "\n",
    "# Load ground truth from .m file\n",
    "def load_ucsd_gt(root):\n",
    "    test_dir = os.path.join(root, 'Test')\n",
    "    m_files = glob.glob(os.path.join(test_dir, '*.m'))\n",
    "    if not m_files:\n",
    "        raise FileNotFoundError(f\"No .m GT files in {test_dir}\")\n",
    "    text = open(m_files[0], 'r').read()\n",
    "    matches = re.findall(r\"TestVideoFile\\{end\\+1\\}\\.gt_frame\\s*=\\s*\\[(\\d+):(\\d+)\\];\", text)\n",
    "    if not matches:\n",
    "        raise ValueError(\"No gt_frame lines found in .m file.\")\n",
    "    return [list(range(int(s), int(e)+1)) for s, e in matches]\n",
    "\n",
    "# Combined Loss (MSE + L1 + MS-SSIM)\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, beta=0.3, gamma=0.2):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.l1 = nn.L1Loss()\n",
    "        self.alpha, self.beta, self.gamma = alpha, beta, gamma\n",
    "\n",
    "    def forward(self, recon, x):\n",
    "        loss_mse = self.mse(recon, x)\n",
    "        loss_l1 = self.l1(recon, x)\n",
    "        x01 = (x + 1) / 2\n",
    "        r01 = (recon + 1) / 2\n",
    "        ssim_val = ssim(r01, x01, data_range=1.0, size_average=True)\n",
    "        loss_ssim = 1 - ssim_val\n",
    "        return self.alpha * loss_mse + self.beta * loss_l1 + self.gamma * loss_ssim\n",
    "\n",
    "# Simplified convolutional autoencoder\n",
    "def conv_autoencoder():\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(1, 32, 3, 2, 1), nn.ReLU(True),\n",
    "        nn.Conv2d(32, 64, 3, 2, 1), nn.ReLU(True),\n",
    "        nn.Conv2d(64, 128, 3, 2, 1), nn.ReLU(True),\n",
    "        nn.ConvTranspose2d(128, 64, 3, 2, 1, 1), nn.ReLU(True),\n",
    "        nn.ConvTranspose2d(64, 32, 3, 2, 1, 1), nn.ReLU(True),\n",
    "        nn.ConvTranspose2d(32, 1, 3, 2, 1, 1), nn.Tanh()\n",
    "    )\n",
    "\n",
    "# Training loop\n",
    "def train_model(model, loader, epochs=50, lr=1e-3):\n",
    "    model.to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "    sched = optim.lr_scheduler.ReduceLROnPlateau(opt, 'min', factor=0.5, patience=5)\n",
    "    crit = CombinedLoss()\n",
    "    for ep in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        tot = 0\n",
    "        for batch in loader:\n",
    "            x = batch[0].to(device) if isinstance(batch, (list, tuple)) else batch.to(device)\n",
    "            opt.zero_grad()\n",
    "            recon = model(x)\n",
    "            loss = crit(recon, x)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            tot += loss.item() * x.size(0)\n",
    "        avg = tot / len(loader.dataset)\n",
    "        sched.step(avg)\n",
    "        print(f\"Epoch {ep}/{epochs}, Loss={avg:.6f}\")\n",
    "    return model\n",
    "\n",
    "# Evaluation\n",
    "def evaluate(model, root, gt_list, bs=32):\n",
    "    model.eval()\n",
    "    scores, labels = [], []\n",
    "    ds = UCSDPed2Dataset(root, 'testing', transform=test_transform, gt_list=gt_list)\n",
    "    loader = DataLoader(ds, batch_size=bs, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            recon = model(x)\n",
    "            err = torch.mean((recon - x)**2, dim=[1,2,3]).cpu().numpy()\n",
    "            scores.extend(err.tolist())\n",
    "            labels.extend(y)\n",
    "    auc = roc_auc_score(labels, scores)\n",
    "    fpr, tpr, th = roc_curve(labels, scores)\n",
    "    thr = th[np.argmax(tpr - fpr)]\n",
    "    preds = [1 if s >= thr else 0 for s in scores]\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    print(f\"AUC={auc:.4f}, Acc={accuracy_score(labels,preds):.4f}, F1={f1_score(labels,preds):.4f}\\nCM:\\n{cm}\")\n",
    "    print(classification_report(labels, preds, target_names=['Normal','Anomaly']))\n",
    "\n",
    "# Main\n",
    "if __name__ == '__main__':\n",
    "    root = '/l/users/zainab.aldhanhani/AI702Project/UCSD_Anomaly_Dataset.v1p2/UCSDped2'\n",
    "    # define transforms with Elastic deformation\n",
    "    train_transform = transforms.Compose([\n",
    "        ElasticTransform(alpha=34, sigma=4, probability=0.5),\n",
    "        transforms.Grayscale(),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Grayscale(),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    gt_list = load_ucsd_gt(root)\n",
    "    train_ds = UCSDPed2Dataset(root, 'training', transform=train_transform, gt_list=gt_list)\n",
    "    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=4)\n",
    "    model = conv_autoencoder()\n",
    "    model = train_model(model, train_loader, epochs=50, lr=1e-3)\n",
    "    torch.save(model.state_dict(), 'ucsdped2_elastic.pth')\n",
    "    evaluate(model, root, gt_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI702project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
